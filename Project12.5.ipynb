{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f8ca24",
   "metadata": {},
   "source": [
    "# Understanding Hired Rides in NYC\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1VERPjEZcC1XSs4-02aM-DbkNr_yaJVbFjLJxaYQswqA/edit#)_\n",
    "\n",
    "_This scaffolding notebook may be used to help setup your final project. It's **totally optional** whether you make use of this or not._\n",
    "\n",
    "_If you do use this notebook, everything provided is optional as well - you may remove or add prose and code as you wish._\n",
    "\n",
    "_Anything in italics (prose) or comments (in code) is meant to provide you with guidance. **Remove the italic lines and provided comments** before submitting the project, if you choose to use this scaffolding. We don't need the guidance when grading._\n",
    "\n",
    "_**All code below should be consider \"pseudo-code\" - not functional by itself, and only a suggestion at the approach.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25627e8d",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project._\n",
    "\n",
    "* Code clarity: make sure the code conforms to:\n",
    "    * [ ] [PEP 8](https://peps.python.org/pep-0008/) - You might find [this resource](https://realpython.com/python-pep8/) helpful as well as [this](https://github.com/dnanhkhoa/nb_black) or [this](https://jupyterlab-code-formatter.readthedocs.io/en/latest/) tool\n",
    "    * [ ] [PEP 257](https://peps.python.org/pep-0257/)\n",
    "    * [ ] Break each task down into logical functions\n",
    "* The following files are submitted for the project (see the project's GDoc for more details):\n",
    "    * [ ] `README.md`\n",
    "    * [ ] `requirements.txt`\n",
    "    * [ ] `.gitignore`\n",
    "    * [ ] `schema.sql`\n",
    "    * [ ] 6 query files (using the `.sql` extension), appropriately named for the purpose of the query\n",
    "    * [x] Jupyter Notebook containing the project (this file!)\n",
    "* [x] You can edit this cell and add a `x` inside the `[ ]` like this task to denote a completed task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75fd94",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66dcde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all import statements needed for the project, for example:\n",
    "\n",
    "import math\n",
    "\n",
    "import bs4\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "import sqlalchemy as db\n",
    "import re\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b622a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f1242c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any constants you might need, for example:\n",
    "\n",
    "TAXI_URL = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "TAXI_ZONES = \"taxi_zones/taxi_zones.shp\"\n",
    "# add other constants to refer to any local data, e.g. uber & weather\n",
    "UBER_CSV = \"uber/uber_rides_sample.csv\"\n",
    "WEATHER_PATH = \"weather\"\n",
    "\n",
    "\n",
    "NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "\n",
    "DATABASE_URL = \"sqlite:///project.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad10ea",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf38168",
   "metadata": {},
   "source": [
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
    "\n",
    "* [ ] Define a function that calculates the distance between two coordinates in kilometers that **only uses the `math` module** from the standard library.\n",
    "* [ ] Taxi data:\n",
    "    * [ ] Use the `re` module, and the packages `requests`, BeautifulSoup (`bs4`), and (optionally) `pandas` to programmatically download the required CSV files & load into memory.\n",
    "    * You may need to do this one file at a time - download, clean, sample. You can cache the sampling by saving it as a CSV file (and thereby freeing up memory on your computer) before moving onto the next file. \n",
    "* [ ] Weather & Uber data:\n",
    "    * [ ] Download the data manually in the link provided in the project doc.\n",
    "* [ ] All data:\n",
    "    * [ ] Load the data using `pandas`\n",
    "    * [ ] Clean the data, including:\n",
    "        * Remove unnecessary columns\n",
    "        * Remove invalid data points (take a moment to consider what's invalid)\n",
    "        * Normalize column names\n",
    "        * (Taxi & Uber data) Remove trips that start and/or end outside the designated [coordinate box](http://bboxfinder.com/#40.560445,-74.242330,40.908524,-73.717047)\n",
    "    * [ ] (Taxi data) Sample the data so that you have roughly the same amount of data points over the given date range for both Taxi data and Uber data.\n",
    "* [ ] Weather data:\n",
    "    * [ ] Split into two `pandas` DataFrames: one for required hourly data, and one for the required daily daya.\n",
    "    * [ ] You may find that the weather data you need later on does not exist at the frequency needed (daily vs hourly). You may calculate/generate samples from one to populate the other. Just document what youâ€™re doing so we can follow along. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32074561",
   "metadata": {},
   "source": [
    "### Calculating distance\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cbbe6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(from_coord, to_coord):\n",
    "    # convert longitude and latitude to radian\n",
    "    lon1, lat1, lon2, lat2 = map(math.radians, from_coord+to_coord) \n",
    "    dlon=lon2-lon1\n",
    "    dlat=lat2-lat1\n",
    "    a=math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
    "    distance=2*math.asin(math.sqrt(a))*6371*1000\n",
    "    distance=round(distance/1000,3)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d6abf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_distance_column(dataframe):\n",
    "    dataframe['distance'] = dataframe.apply(lambda x: calculate_distance((\n",
    "        x['pickup_longitude'], x['pickup_latitude']), (x['dropoff_longitude'], x['dropoff_latitude'])), axis=1)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93daa717",
   "metadata": {},
   "source": [
    "### Processing Taxi Data\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbd0d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_taxi_parquet_urls(taxi_url):\n",
    "    response = requests.get(taxi_url)\n",
    "    html = response.content\n",
    "    results_page = bs4.BeautifulSoup(html, 'html.parser')\n",
    "    links = results_page.find_all('a',title=r'Yellow Taxi Trip Records')\n",
    "    pattern = r'yellow_tripdata_(2009|201[0-4]|2015-0[1-6])'\n",
    "    urls = [link.get('href') for link in links if re.search(pattern,link.get('href'))]\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f40130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_month_taxi_data(taxi_data_url):\n",
    "    pattern = r'yellow_tripdata_[0-9]{4}-[0-9]{2}'\n",
    "    name = re.search(pattern,taxi_data_url).group()\n",
    "    path = os.path.join(os.getcwd(),'taxi',name+'.csv')\n",
    "    if os.path.exists(path):\n",
    "        print('read',name)\n",
    "        df = pd.read_csv(path)\n",
    "    else:\n",
    "        print('download',name)\n",
    "        df = pd.read_parquet(taxi_data_url, engine='pyarrow')\n",
    "        df.to_csv(path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a96656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_taxi_data(row_taxi_data,taxi_zones):\n",
    "    taxi_data = pd.DataFrame()\n",
    "    if 'tpep_pickup_datetime' in row_taxi_data.columns:\n",
    "        taxi_data['pickup_datetime'] = row_taxi_data['tpep_pickup_datetime']\n",
    "    elif 'Trip_Pickup_DateTime' in row_taxi_data.columns:\n",
    "        taxi_data['pickup_datetime'] = row_taxi_data['Trip_Pickup_DateTime']\n",
    "    elif 'pickup_datetime' in row_taxi_data.columns:\n",
    "        taxi_data['pickup_datetime'] = row_taxi_data['pickup_datetime']\n",
    "    else:\n",
    "        raise ValueError('No pickup_datetime')\n",
    "    if 'PULocationID' and 'DOLocationID' in row_taxi_data.columns:\n",
    "        taxi_data['PULocationID'] = row_taxi_data['PULocationID']\n",
    "        taxi_data['DOLocationID'] = row_taxi_data['DOLocationID']\n",
    "        taxi_data = taxi_data.merge(taxi_zones[['LocationID','lon','lat']].set_index('LocationID'),\n",
    "                                    left_on='PULocationID', right_on='LocationID')\n",
    "        taxi_data = taxi_data.rename(columns={'lon': 'pickup_longitude', 'lat': 'pickup_latitude'})\n",
    "        taxi_data = taxi_data.merge(taxi_zones[['LocationID','lon','lat']].set_index('LocationID'),\n",
    "                                    left_on='DOLocationID', right_on='LocationID')\n",
    "        taxi_data = taxi_data.rename(columns={'lon': 'dropoff_longitude', 'lat': 'dropoff_latitude'})\n",
    "\n",
    "        taxi_data = taxi_data.drop(columns=['PULocationID','DOLocationID'])\n",
    "    elif 'Start_Lon' and 'Start_Lat' and 'End_Lon' and 'End_Lat' in row_taxi_data.columns:\n",
    "        taxi_data['pickup_longitude'] = row_taxi_data['Start_Lon']\n",
    "        taxi_data['pickup_latitude'] = row_taxi_data['Start_Lat']\n",
    "        taxi_data['dropoff_longitude'] = row_taxi_data['End_Lon']\n",
    "        taxi_data['dropoff_latitude'] = row_taxi_data['End_Lat']\n",
    "    elif 'pickup_longitude' and 'pickup_latitude' and 'dropoff_longitude' and 'dropoff_latitude' in row_taxi_data.columns:\n",
    "        taxi_data['pickup_longitude'] = row_taxi_data['pickup_longitude']\n",
    "        taxi_data['pickup_latitude'] = row_taxi_data['pickup_latitude']\n",
    "        taxi_data['dropoff_longitude'] = row_taxi_data['dropoff_longitude']\n",
    "        taxi_data['dropoff_latitude'] = row_taxi_data['dropoff_latitude']\n",
    "    else:\n",
    "        raise ValueError('No pickup_datetime')\n",
    "\n",
    "    taxi_data['pickup_datetime'] = pd.to_datetime(taxi_data['pickup_datetime'])\n",
    "    taxi_data = taxi_data.dropna()\n",
    "    \n",
    "    \n",
    "    #pick up in bounding box \n",
    "    taxi_data = taxi_data[(taxi_data['pickup_longitude']>NEW_YORK_BOX_COORDS[0][1])\n",
    "                          & (taxi_data['pickup_longitude']<NEW_YORK_BOX_COORDS[1][1])]\n",
    "    taxi_data = taxi_data[(taxi_data['pickup_latitude']>NEW_YORK_BOX_COORDS[0][0])\n",
    "                          & (taxi_data['pickup_latitude']<NEW_YORK_BOX_COORDS[1][0])]\n",
    "    #drop off in bounding box  \n",
    "    taxi_data = taxi_data[(taxi_data['dropoff_longitude']>NEW_YORK_BOX_COORDS[0][1])\n",
    "                          & (taxi_data['dropoff_longitude']<NEW_YORK_BOX_COORDS[1][1])]\n",
    "    taxi_data = taxi_data[(taxi_data['dropoff_latitude']>NEW_YORK_BOX_COORDS[0][0])\n",
    "                          & (taxi_data['dropoff_latitude']<NEW_YORK_BOX_COORDS[1][0])]\n",
    "    \n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35c9c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_taxi_data():\n",
    "    all_csv_urls = find_taxi_parquet_urls(TAXI_URL)\n",
    "    taxi_zone_df = gpd.read_file(TAXI_ZONES)\n",
    "    taxi_zone_df = taxi_zone_df.to_crs(4326)\n",
    "    taxi_zone_df['lon'] = taxi_zone_df.centroid.x  \n",
    "    taxi_zone_df['lat'] = taxi_zone_df.centroid.y\n",
    "    all_taxi_dataframes = []\n",
    "    for csv_url in all_csv_urls:\n",
    "        month_taxi_dataframe = get_month_taxi_data(csv_url)\n",
    "        month_taxi_dataframe = clean_month_taxi_data(month_taxi_dataframe,taxi_zone_df)\n",
    "        month_taxi_dataframe = add_distance_column(month_taxi_dataframe)\n",
    "        all_taxi_dataframes.append(month_taxi_dataframe.sample(30000,random_state=1))\n",
    "        \n",
    "    # create one gigantic dataframe with data from every month needed\n",
    "    all_taxi_data = pd.concat(all_taxi_dataframes)\n",
    "    all_taxi_data = all_taxi_data.sample(200000,random_state=1)\n",
    "    return all_taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81254f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_12324\\1040642967.py:5: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zone_df['lon'] = taxi_zone_df.centroid.x\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_12324\\1040642967.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zone_df['lat'] = taxi_zone_df.centroid.y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read yellow_tripdata_2015-01\n",
      "read yellow_tripdata_2015-02\n",
      "read yellow_tripdata_2015-03\n",
      "read yellow_tripdata_2015-04\n",
      "read yellow_tripdata_2015-05\n",
      "read yellow_tripdata_2015-06\n",
      "read yellow_tripdata_2014-01\n",
      "read yellow_tripdata_2014-02\n",
      "read yellow_tripdata_2014-03\n",
      "read yellow_tripdata_2014-04\n",
      "read yellow_tripdata_2014-05\n",
      "read yellow_tripdata_2014-06\n",
      "read yellow_tripdata_2014-07\n",
      "read yellow_tripdata_2014-08\n",
      "read yellow_tripdata_2014-09\n",
      "read yellow_tripdata_2014-10\n",
      "read yellow_tripdata_2014-11\n",
      "read yellow_tripdata_2014-12\n",
      "read yellow_tripdata_2013-01\n",
      "read yellow_tripdata_2013-02\n",
      "read yellow_tripdata_2013-03\n",
      "read yellow_tripdata_2013-04\n",
      "read yellow_tripdata_2013-05\n",
      "read yellow_tripdata_2013-06\n",
      "read yellow_tripdata_2013-07\n",
      "read yellow_tripdata_2013-08\n",
      "read yellow_tripdata_2013-09\n",
      "read yellow_tripdata_2013-10\n",
      "read yellow_tripdata_2013-11\n",
      "read yellow_tripdata_2013-12\n",
      "read yellow_tripdata_2012-01\n",
      "read yellow_tripdata_2012-02\n",
      "read yellow_tripdata_2012-03\n",
      "read yellow_tripdata_2012-04\n",
      "read yellow_tripdata_2012-05\n",
      "read yellow_tripdata_2012-06\n",
      "read yellow_tripdata_2012-07\n",
      "read yellow_tripdata_2012-08\n",
      "read yellow_tripdata_2012-09\n",
      "read yellow_tripdata_2012-10\n",
      "read yellow_tripdata_2012-11\n",
      "read yellow_tripdata_2012-12\n",
      "read yellow_tripdata_2011-01\n",
      "read yellow_tripdata_2011-02\n",
      "read yellow_tripdata_2011-03\n",
      "read yellow_tripdata_2011-04\n",
      "read yellow_tripdata_2011-05\n",
      "read yellow_tripdata_2011-06\n",
      "read yellow_tripdata_2011-07\n",
      "read yellow_tripdata_2011-08\n",
      "read yellow_tripdata_2011-09\n",
      "read yellow_tripdata_2011-10\n",
      "read yellow_tripdata_2011-11\n",
      "read yellow_tripdata_2011-12\n",
      "read yellow_tripdata_2010-01\n",
      "read yellow_tripdata_2010-02\n",
      "read yellow_tripdata_2010-03\n",
      "read yellow_tripdata_2010-04\n",
      "read yellow_tripdata_2010-05\n",
      "read yellow_tripdata_2010-06\n",
      "read yellow_tripdata_2010-07\n",
      "read yellow_tripdata_2010-08\n",
      "read yellow_tripdata_2010-09\n",
      "read yellow_tripdata_2010-10\n",
      "read yellow_tripdata_2010-11\n",
      "read yellow_tripdata_2010-12\n",
      "read yellow_tripdata_2009-01\n",
      "read yellow_tripdata_2009-02\n",
      "read yellow_tripdata_2009-03\n",
      "read yellow_tripdata_2009-04\n",
      "read yellow_tripdata_2009-05\n",
      "read yellow_tripdata_2009-06\n",
      "read yellow_tripdata_2009-07\n",
      "read yellow_tripdata_2009-08\n",
      "read yellow_tripdata_2009-09\n",
      "read yellow_tripdata_2009-10\n",
      "read yellow_tripdata_2009-11\n",
      "read yellow_tripdata_2009-12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-12 23:07:25</td>\n",
       "      <td>-73.977698</td>\n",
       "      <td>40.758028</td>\n",
       "      <td>-73.981532</td>\n",
       "      <td>40.773633</td>\n",
       "      <td>1.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-28 20:01:08</td>\n",
       "      <td>-73.977698</td>\n",
       "      <td>40.758028</td>\n",
       "      <td>-73.981532</td>\n",
       "      <td>40.773633</td>\n",
       "      <td>1.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-27 19:37:57</td>\n",
       "      <td>-73.977698</td>\n",
       "      <td>40.758028</td>\n",
       "      <td>-73.981532</td>\n",
       "      <td>40.773633</td>\n",
       "      <td>1.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-07 19:02:57</td>\n",
       "      <td>-73.984196</td>\n",
       "      <td>40.759818</td>\n",
       "      <td>-73.981532</td>\n",
       "      <td>40.773633</td>\n",
       "      <td>1.553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-16 13:45:53</td>\n",
       "      <td>-73.984196</td>\n",
       "      <td>40.759818</td>\n",
       "      <td>-73.981532</td>\n",
       "      <td>40.773633</td>\n",
       "      <td>1.553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>2009-12-10 11:30:34</td>\n",
       "      <td>-73.991986</td>\n",
       "      <td>40.749751</td>\n",
       "      <td>-73.996724</td>\n",
       "      <td>40.742683</td>\n",
       "      <td>0.881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>2009-12-27 00:01:49</td>\n",
       "      <td>-73.982310</td>\n",
       "      <td>40.772300</td>\n",
       "      <td>-73.964232</td>\n",
       "      <td>40.809630</td>\n",
       "      <td>4.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597</th>\n",
       "      <td>2009-12-06 16:18:46</td>\n",
       "      <td>-73.993775</td>\n",
       "      <td>40.751384</td>\n",
       "      <td>-73.993252</td>\n",
       "      <td>40.752434</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>2009-12-12 13:03:00</td>\n",
       "      <td>-73.969870</td>\n",
       "      <td>40.757927</td>\n",
       "      <td>-74.001047</td>\n",
       "      <td>40.722898</td>\n",
       "      <td>4.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>2009-12-04 18:53:45</td>\n",
       "      <td>-73.996522</td>\n",
       "      <td>40.725498</td>\n",
       "      <td>-73.994269</td>\n",
       "      <td>40.740886</td>\n",
       "      <td>1.722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197899 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "0    2015-01-12 23:07:25        -73.977698        40.758028   \n",
       "1    2015-01-28 20:01:08        -73.977698        40.758028   \n",
       "2    2015-01-27 19:37:57        -73.977698        40.758028   \n",
       "3    2015-01-07 19:02:57        -73.984196        40.759818   \n",
       "4    2015-01-16 13:45:53        -73.984196        40.759818   \n",
       "...                  ...               ...              ...   \n",
       "2595 2009-12-10 11:30:34        -73.991986        40.749751   \n",
       "2596 2009-12-27 00:01:49        -73.982310        40.772300   \n",
       "2597 2009-12-06 16:18:46        -73.993775        40.751384   \n",
       "2598 2009-12-12 13:03:00        -73.969870        40.757927   \n",
       "2599 2009-12-04 18:53:45        -73.996522        40.725498   \n",
       "\n",
       "      dropoff_longitude  dropoff_latitude  distance  \n",
       "0            -73.981532         40.773633     1.765  \n",
       "1            -73.981532         40.773633     1.765  \n",
       "2            -73.981532         40.773633     1.765  \n",
       "3            -73.981532         40.773633     1.553  \n",
       "4            -73.981532         40.773633     1.553  \n",
       "...                 ...               ...       ...  \n",
       "2595         -73.996724         40.742683     0.881  \n",
       "2596         -73.964232         40.809630     4.421  \n",
       "2597         -73.993252         40.752434     0.125  \n",
       "2598         -74.001047         40.722898     4.698  \n",
       "2599         -73.994269         40.740886     1.722  \n",
       "\n",
       "[197899 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data = get_and_clean_taxi_data()\n",
    "taxi_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094b4d6d",
   "metadata": {},
   "source": [
    "### Processing Uber Data\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e60937c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_uber_data(csv_file):\n",
    "    uber_data = pd.read_csv(csv_file)\n",
    "    uber_data = uber_data.drop(columns=['Unnamed: 0','key','fare_amount','passenger_count'])\n",
    "    uber_data = uber_data.dropna()\n",
    "    \n",
    "    #pick up in bounding box \n",
    "    uber_data = uber_data[(uber_data['pickup_longitude']>NEW_YORK_BOX_COORDS[0][1]) & (uber_data['pickup_longitude']<NEW_YORK_BOX_COORDS[1][1])]\n",
    "    uber_data = uber_data[(uber_data['pickup_latitude']>NEW_YORK_BOX_COORDS[0][0]) & (uber_data['pickup_latitude']<NEW_YORK_BOX_COORDS[1][0])]\n",
    "    #drop off in bounding box  \n",
    "    uber_data = uber_data[(uber_data['dropoff_longitude']>NEW_YORK_BOX_COORDS[0][1]) & (uber_data['dropoff_longitude']<NEW_YORK_BOX_COORDS[1][1])]\n",
    "    uber_data = uber_data[(uber_data['dropoff_latitude']>NEW_YORK_BOX_COORDS[0][0]) & (uber_data['dropoff_latitude']<NEW_YORK_BOX_COORDS[1][0])]\n",
    "    uber_data['pickup_datetime'] = pd.to_datetime(uber_data['pickup_datetime'])\n",
    "    \n",
    "    return uber_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f836f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uber_data():\n",
    "    uber_dataframe = clean_uber_data(UBER_CSV)\n",
    "    uber_dataframe = add_distance_column(uber_dataframe)\n",
    "    return uber_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "078476b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-07 19:52:06+00:00</td>\n",
       "      <td>-73.999817</td>\n",
       "      <td>40.738354</td>\n",
       "      <td>-73.999512</td>\n",
       "      <td>40.723217</td>\n",
       "      <td>1.683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-07-17 20:04:56+00:00</td>\n",
       "      <td>-73.994355</td>\n",
       "      <td>40.728225</td>\n",
       "      <td>-73.994710</td>\n",
       "      <td>40.750325</td>\n",
       "      <td>2.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-08-24 21:45:00+00:00</td>\n",
       "      <td>-74.005043</td>\n",
       "      <td>40.740770</td>\n",
       "      <td>-73.962565</td>\n",
       "      <td>40.772647</td>\n",
       "      <td>5.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-06-26 08:22:21+00:00</td>\n",
       "      <td>-73.976124</td>\n",
       "      <td>40.790844</td>\n",
       "      <td>-73.965316</td>\n",
       "      <td>40.803349</td>\n",
       "      <td>1.662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-28 17:47:00+00:00</td>\n",
       "      <td>-73.925023</td>\n",
       "      <td>40.744085</td>\n",
       "      <td>-73.973082</td>\n",
       "      <td>40.761247</td>\n",
       "      <td>4.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>2012-10-28 10:49:00+00:00</td>\n",
       "      <td>-73.987042</td>\n",
       "      <td>40.739367</td>\n",
       "      <td>-73.986525</td>\n",
       "      <td>40.740297</td>\n",
       "      <td>0.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>2014-03-14 01:09:00+00:00</td>\n",
       "      <td>-73.984722</td>\n",
       "      <td>40.736837</td>\n",
       "      <td>-74.006672</td>\n",
       "      <td>40.739620</td>\n",
       "      <td>1.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>2009-06-29 00:42:00+00:00</td>\n",
       "      <td>-73.986017</td>\n",
       "      <td>40.756487</td>\n",
       "      <td>-73.858957</td>\n",
       "      <td>40.692588</td>\n",
       "      <td>12.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>2015-05-20 14:56:25+00:00</td>\n",
       "      <td>-73.997124</td>\n",
       "      <td>40.725452</td>\n",
       "      <td>-73.983215</td>\n",
       "      <td>40.695415</td>\n",
       "      <td>3.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>2010-05-15 04:08:00+00:00</td>\n",
       "      <td>-73.984395</td>\n",
       "      <td>40.720077</td>\n",
       "      <td>-73.985508</td>\n",
       "      <td>40.768793</td>\n",
       "      <td>5.418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195472 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "0      2015-05-07 19:52:06+00:00        -73.999817        40.738354   \n",
       "1      2009-07-17 20:04:56+00:00        -73.994355        40.728225   \n",
       "2      2009-08-24 21:45:00+00:00        -74.005043        40.740770   \n",
       "3      2009-06-26 08:22:21+00:00        -73.976124        40.790844   \n",
       "4      2014-08-28 17:47:00+00:00        -73.925023        40.744085   \n",
       "...                          ...               ...              ...   \n",
       "199995 2012-10-28 10:49:00+00:00        -73.987042        40.739367   \n",
       "199996 2014-03-14 01:09:00+00:00        -73.984722        40.736837   \n",
       "199997 2009-06-29 00:42:00+00:00        -73.986017        40.756487   \n",
       "199998 2015-05-20 14:56:25+00:00        -73.997124        40.725452   \n",
       "199999 2010-05-15 04:08:00+00:00        -73.984395        40.720077   \n",
       "\n",
       "        dropoff_longitude  dropoff_latitude  distance  \n",
       "0              -73.999512         40.723217     1.683  \n",
       "1              -73.994710         40.750325     2.458  \n",
       "2              -73.962565         40.772647     5.036  \n",
       "3              -73.965316         40.803349     1.662  \n",
       "4              -73.973082         40.761247     4.475  \n",
       "...                   ...               ...       ...  \n",
       "199995         -73.986525         40.740297     0.112  \n",
       "199996         -74.006672         40.739620     1.875  \n",
       "199997         -73.858957         40.692588    12.850  \n",
       "199998         -73.983215         40.695415     3.540  \n",
       "199999         -73.985508         40.768793     5.418  \n",
       "\n",
       "[195472 rows x 6 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_data = get_uber_data()\n",
    "uber_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a15cbb",
   "metadata": {},
   "source": [
    "### Processing Weather Data\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76e864ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_hourly(csv_file):\n",
    "    whole_data = pd.read_csv(csv_file)\n",
    "    whole_data['REPORT_TYPE'] = whole_data['REPORT_TYPE'].astype(str)\n",
    "    whole_data['DATE'] = pd.to_datetime(whole_data['DATE'])\n",
    "    \n",
    "    hourly_data = whole_data[whole_data['REPORT_TYPE'] != 'SOD  ']\n",
    "    hourly_data = hourly_data[['DATE','HourlyPrecipitation','HourlyWindSpeed']]\n",
    "    hourly_data['HourlyPrecipitation'] = pd.to_numeric(hourly_data['HourlyPrecipitation'], errors='coerce')\n",
    "    hourly_data['HourlyWindSpeed'] = pd.to_numeric(hourly_data['HourlyWindSpeed'], errors='coerce')\n",
    "    hourly_data['HourlyPrecipitation'].fillna(0, inplace=True)\n",
    "    hourly_data['HourlyWindSpeed'].fillna(0, inplace=True)\n",
    "    hourly_data = hourly_data.rename(columns={'DATE': 'datetime'})\n",
    "    hourly_data = hourly_data.rename(columns={'HourlyPrecipitation':'hourly_precipitation','HourlyWindSpeed':'hourly_wind_speed'})\n",
    "    \n",
    "    return hourly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0687581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_daily(csv_file):\n",
    "    whole_data = pd.read_csv(csv_file)\n",
    "    whole_data['REPORT_TYPE'] = whole_data['REPORT_TYPE'].astype(str)\n",
    "    whole_data['DATE'] = pd.to_datetime(whole_data['DATE'])\n",
    "    whole_data['DATE'] = whole_data['DATE'].dt.date\n",
    "    \n",
    "    hourly_data = whole_data[whole_data['REPORT_TYPE'] != 'SOD  ']\n",
    "    hourly_data = hourly_data[['DATE','HourlyPrecipitation','HourlyWindSpeed']]\n",
    "    hourly_data['HourlyPrecipitation'] = pd.to_numeric(hourly_data['HourlyPrecipitation'], errors='coerce')\n",
    "    hourly_data['HourlyWindSpeed'] = pd.to_numeric(hourly_data['HourlyWindSpeed'], errors='coerce')\n",
    "    hourly_data['HourlyPrecipitation'].fillna(0, inplace=True)\n",
    "    hourly_data = hourly_data.groupby('DATE', as_index=False).agg({'HourlyWindSpeed': 'mean', 'HourlyPrecipitation': 'sum'})\n",
    "    \n",
    "    daily_data = whole_data[whole_data['REPORT_TYPE'] == 'SOD  ']\n",
    "    daily_data = daily_data[['DATE','Sunrise','Sunset']]\n",
    "    daily_data['Sunrise'] = pd.to_numeric(daily_data['Sunrise'], errors='coerce')\n",
    "    daily_data['Sunset'] = pd.to_numeric(daily_data['Sunset'], errors='coerce')\n",
    "    \n",
    "    daily_data = hourly_data.merge(daily_data, on='DATE',how='left')\n",
    "    daily_data.fillna(method='ffill',inplace=True)\n",
    "    daily_data.fillna(method='bfill',inplace=True)\n",
    "    daily_data = daily_data.rename(columns={'DATE': 'date'})\n",
    "    daily_data = daily_data.rename(columns={'HourlyPrecipitation':'daily_precipitation', 'HourlyWindSpeed':'daily_wind_speed'})\n",
    "    daily_data = daily_data.rename(columns={'Sunrise': 'sunrise', 'Sunset': 'sunset'})\n",
    "    \n",
    "    return daily_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ef8945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_weather_data():\n",
    "    hourly_dataframes = []\n",
    "    daily_dataframes = []\n",
    "    \n",
    "    weather_csv_files = glob.glob(os.path.join(os.getcwd(), WEATHER_PATH, \"*.csv\"))\n",
    "    \n",
    "    for csv_file in weather_csv_files:\n",
    "        hourly_dataframe = clean_month_weather_data_hourly(csv_file)\n",
    "        daily_dataframe = clean_month_weather_data_daily(csv_file)\n",
    "        hourly_dataframes.append(hourly_dataframe)\n",
    "        daily_dataframes.append(daily_dataframe)\n",
    "        \n",
    "    # create two dataframes with hourly & daily data from every month\n",
    "    hourly_data = pd.concat(hourly_dataframes)\n",
    "    daily_data = pd.concat(daily_dataframes)\n",
    "    \n",
    "    return hourly_data, daily_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8965941f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_12324\\156112435.py:2: DtypeWarning: Columns (9,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  whole_data = pd.read_csv(csv_file)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_12324\\2991833665.py:2: DtypeWarning: Columns (9,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  whole_data = pd.read_csv(csv_file)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_12324\\156112435.py:2: DtypeWarning: Columns (8,9,10,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  whole_data = pd.read_csv(csv_file)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_12324\\2991833665.py:2: DtypeWarning: Columns (8,9,10,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  whole_data = pd.read_csv(csv_file)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_12324\\156112435.py:2: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  whole_data = pd.read_csv(csv_file)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_12324\\2991833665.py:2: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  whole_data = pd.read_csv(csv_file)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_12324\\156112435.py:2: DtypeWarning: Columns (7,8,9,10,17,18,42,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  whole_data = pd.read_csv(csv_file)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_12324\\2991833665.py:2: DtypeWarning: Columns (7,8,9,10,17,18,42,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  whole_data = pd.read_csv(csv_file)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_12324\\156112435.py:2: DtypeWarning: Columns (17,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  whole_data = pd.read_csv(csv_file)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_12324\\2991833665.py:2: DtypeWarning: Columns (17,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  whole_data = pd.read_csv(csv_file)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_12324\\156112435.py:2: DtypeWarning: Columns (8,9,17,18,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  whole_data = pd.read_csv(csv_file)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_12324\\2991833665.py:2: DtypeWarning: Columns (8,9,17,18,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  whole_data = pd.read_csv(csv_file)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_12324\\156112435.py:2: DtypeWarning: Columns (10,41,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  whole_data = pd.read_csv(csv_file)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_12324\\2991833665.py:2: DtypeWarning: Columns (10,41,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  whole_data = pd.read_csv(csv_file)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>hourly_precipitation</th>\n",
       "      <th>hourly_wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-01 00:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-01 01:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-01 02:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-01 03:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-01 04:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11381</th>\n",
       "      <td>2015-12-31 20:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11382</th>\n",
       "      <td>2015-12-31 21:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11383</th>\n",
       "      <td>2015-12-31 22:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11384</th>\n",
       "      <td>2015-12-31 23:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11386</th>\n",
       "      <td>2015-12-31 23:59:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76146 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 datetime  hourly_precipitation  hourly_wind_speed\n",
       "0     2009-01-01 00:51:00                   0.0               18.0\n",
       "1     2009-01-01 01:51:00                   0.0               18.0\n",
       "2     2009-01-01 02:51:00                   0.0               18.0\n",
       "3     2009-01-01 03:51:00                   0.0                8.0\n",
       "4     2009-01-01 04:51:00                   0.0               11.0\n",
       "...                   ...                   ...                ...\n",
       "11381 2015-12-31 20:51:00                   0.0               10.0\n",
       "11382 2015-12-31 21:51:00                   0.0                0.0\n",
       "11383 2015-12-31 22:51:00                   0.0                7.0\n",
       "11384 2015-12-31 23:51:00                   0.0                5.0\n",
       "11386 2015-12-31 23:59:00                   0.0                0.0\n",
       "\n",
       "[76146 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_weather_data, daily_weather_data = load_and_clean_weather_data()\n",
    "hourly_weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e4d05f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>daily_wind_speed</th>\n",
       "      <th>daily_precipitation</th>\n",
       "      <th>sunrise</th>\n",
       "      <th>sunset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>11.041667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>6.806452</td>\n",
       "      <td>0.00</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>9.875000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-04</td>\n",
       "      <td>7.370370</td>\n",
       "      <td>0.00</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>6.925926</td>\n",
       "      <td>0.00</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>4.911111</td>\n",
       "      <td>0.17</td>\n",
       "      <td>719.0</td>\n",
       "      <td>1635.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>2015-12-28</td>\n",
       "      <td>8.208333</td>\n",
       "      <td>0.03</td>\n",
       "      <td>719.0</td>\n",
       "      <td>1636.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>2015-12-29</td>\n",
       "      <td>7.787234</td>\n",
       "      <td>0.93</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1636.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2015-12-30</td>\n",
       "      <td>4.184211</td>\n",
       "      <td>0.29</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1637.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>4.741935</td>\n",
       "      <td>0.08</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1638.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2551 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  daily_wind_speed  daily_precipitation  sunrise  sunset\n",
       "0    2009-01-01         11.041667                 0.00    720.0  1640.0\n",
       "1    2009-01-02          6.806452                 0.00    720.0  1640.0\n",
       "2    2009-01-03          9.875000                 0.00    720.0  1640.0\n",
       "3    2009-01-04          7.370370                 0.00    720.0  1640.0\n",
       "4    2009-01-05          6.925926                 0.00    720.0  1640.0\n",
       "..          ...               ...                  ...      ...     ...\n",
       "360  2015-12-27          4.911111                 0.17    719.0  1635.0\n",
       "361  2015-12-28          8.208333                 0.03    719.0  1636.0\n",
       "362  2015-12-29          7.787234                 0.93    720.0  1636.0\n",
       "363  2015-12-30          4.184211                 0.29    720.0  1637.0\n",
       "364  2015-12-31          4.741935                 0.08    720.0  1638.0\n",
       "\n",
       "[2551 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ae82ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-12 23:07:25</td>\n",
       "      <td>-73.977698</td>\n",
       "      <td>40.758028</td>\n",
       "      <td>-73.981532</td>\n",
       "      <td>40.773633</td>\n",
       "      <td>1.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-28 20:01:08</td>\n",
       "      <td>-73.977698</td>\n",
       "      <td>40.758028</td>\n",
       "      <td>-73.981532</td>\n",
       "      <td>40.773633</td>\n",
       "      <td>1.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-27 19:37:57</td>\n",
       "      <td>-73.977698</td>\n",
       "      <td>40.758028</td>\n",
       "      <td>-73.981532</td>\n",
       "      <td>40.773633</td>\n",
       "      <td>1.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-07 19:02:57</td>\n",
       "      <td>-73.984196</td>\n",
       "      <td>40.759818</td>\n",
       "      <td>-73.981532</td>\n",
       "      <td>40.773633</td>\n",
       "      <td>1.553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-16 13:45:53</td>\n",
       "      <td>-73.984196</td>\n",
       "      <td>40.759818</td>\n",
       "      <td>-73.981532</td>\n",
       "      <td>40.773633</td>\n",
       "      <td>1.553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>2009-12-10 11:30:34</td>\n",
       "      <td>-73.991986</td>\n",
       "      <td>40.749751</td>\n",
       "      <td>-73.996724</td>\n",
       "      <td>40.742683</td>\n",
       "      <td>0.881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>2009-12-27 00:01:49</td>\n",
       "      <td>-73.982310</td>\n",
       "      <td>40.772300</td>\n",
       "      <td>-73.964232</td>\n",
       "      <td>40.809630</td>\n",
       "      <td>4.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597</th>\n",
       "      <td>2009-12-06 16:18:46</td>\n",
       "      <td>-73.993775</td>\n",
       "      <td>40.751384</td>\n",
       "      <td>-73.993252</td>\n",
       "      <td>40.752434</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>2009-12-12 13:03:00</td>\n",
       "      <td>-73.969870</td>\n",
       "      <td>40.757927</td>\n",
       "      <td>-74.001047</td>\n",
       "      <td>40.722898</td>\n",
       "      <td>4.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>2009-12-04 18:53:45</td>\n",
       "      <td>-73.996522</td>\n",
       "      <td>40.725498</td>\n",
       "      <td>-73.994269</td>\n",
       "      <td>40.740886</td>\n",
       "      <td>1.722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197899 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "0    2015-01-12 23:07:25        -73.977698        40.758028   \n",
       "1    2015-01-28 20:01:08        -73.977698        40.758028   \n",
       "2    2015-01-27 19:37:57        -73.977698        40.758028   \n",
       "3    2015-01-07 19:02:57        -73.984196        40.759818   \n",
       "4    2015-01-16 13:45:53        -73.984196        40.759818   \n",
       "...                  ...               ...              ...   \n",
       "2595 2009-12-10 11:30:34        -73.991986        40.749751   \n",
       "2596 2009-12-27 00:01:49        -73.982310        40.772300   \n",
       "2597 2009-12-06 16:18:46        -73.993775        40.751384   \n",
       "2598 2009-12-12 13:03:00        -73.969870        40.757927   \n",
       "2599 2009-12-04 18:53:45        -73.996522        40.725498   \n",
       "\n",
       "      dropoff_longitude  dropoff_latitude  distance  \n",
       "0            -73.981532         40.773633     1.765  \n",
       "1            -73.981532         40.773633     1.765  \n",
       "2            -73.981532         40.773633     1.765  \n",
       "3            -73.981532         40.773633     1.553  \n",
       "4            -73.981532         40.773633     1.553  \n",
       "...                 ...               ...       ...  \n",
       "2595         -73.996724         40.742683     0.881  \n",
       "2596         -73.964232         40.809630     4.421  \n",
       "2597         -73.993252         40.752434     0.125  \n",
       "2598         -74.001047         40.722898     4.698  \n",
       "2599         -73.994269         40.740886     1.722  \n",
       "\n",
       "[197899 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eaa8f1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-07 19:52:06+00:00</td>\n",
       "      <td>-73.999817</td>\n",
       "      <td>40.738354</td>\n",
       "      <td>-73.999512</td>\n",
       "      <td>40.723217</td>\n",
       "      <td>1.683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-07-17 20:04:56+00:00</td>\n",
       "      <td>-73.994355</td>\n",
       "      <td>40.728225</td>\n",
       "      <td>-73.994710</td>\n",
       "      <td>40.750325</td>\n",
       "      <td>2.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-08-24 21:45:00+00:00</td>\n",
       "      <td>-74.005043</td>\n",
       "      <td>40.740770</td>\n",
       "      <td>-73.962565</td>\n",
       "      <td>40.772647</td>\n",
       "      <td>5.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-06-26 08:22:21+00:00</td>\n",
       "      <td>-73.976124</td>\n",
       "      <td>40.790844</td>\n",
       "      <td>-73.965316</td>\n",
       "      <td>40.803349</td>\n",
       "      <td>1.662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-28 17:47:00+00:00</td>\n",
       "      <td>-73.925023</td>\n",
       "      <td>40.744085</td>\n",
       "      <td>-73.973082</td>\n",
       "      <td>40.761247</td>\n",
       "      <td>4.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>2012-10-28 10:49:00+00:00</td>\n",
       "      <td>-73.987042</td>\n",
       "      <td>40.739367</td>\n",
       "      <td>-73.986525</td>\n",
       "      <td>40.740297</td>\n",
       "      <td>0.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>2014-03-14 01:09:00+00:00</td>\n",
       "      <td>-73.984722</td>\n",
       "      <td>40.736837</td>\n",
       "      <td>-74.006672</td>\n",
       "      <td>40.739620</td>\n",
       "      <td>1.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>2009-06-29 00:42:00+00:00</td>\n",
       "      <td>-73.986017</td>\n",
       "      <td>40.756487</td>\n",
       "      <td>-73.858957</td>\n",
       "      <td>40.692588</td>\n",
       "      <td>12.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>2015-05-20 14:56:25+00:00</td>\n",
       "      <td>-73.997124</td>\n",
       "      <td>40.725452</td>\n",
       "      <td>-73.983215</td>\n",
       "      <td>40.695415</td>\n",
       "      <td>3.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>2010-05-15 04:08:00+00:00</td>\n",
       "      <td>-73.984395</td>\n",
       "      <td>40.720077</td>\n",
       "      <td>-73.985508</td>\n",
       "      <td>40.768793</td>\n",
       "      <td>5.418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195472 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "0      2015-05-07 19:52:06+00:00        -73.999817        40.738354   \n",
       "1      2009-07-17 20:04:56+00:00        -73.994355        40.728225   \n",
       "2      2009-08-24 21:45:00+00:00        -74.005043        40.740770   \n",
       "3      2009-06-26 08:22:21+00:00        -73.976124        40.790844   \n",
       "4      2014-08-28 17:47:00+00:00        -73.925023        40.744085   \n",
       "...                          ...               ...              ...   \n",
       "199995 2012-10-28 10:49:00+00:00        -73.987042        40.739367   \n",
       "199996 2014-03-14 01:09:00+00:00        -73.984722        40.736837   \n",
       "199997 2009-06-29 00:42:00+00:00        -73.986017        40.756487   \n",
       "199998 2015-05-20 14:56:25+00:00        -73.997124        40.725452   \n",
       "199999 2010-05-15 04:08:00+00:00        -73.984395        40.720077   \n",
       "\n",
       "        dropoff_longitude  dropoff_latitude  distance  \n",
       "0              -73.999512         40.723217     1.683  \n",
       "1              -73.994710         40.750325     2.458  \n",
       "2              -73.962565         40.772647     5.036  \n",
       "3              -73.965316         40.803349     1.662  \n",
       "4              -73.973082         40.761247     4.475  \n",
       "...                   ...               ...       ...  \n",
       "199995         -73.986525         40.740297     0.112  \n",
       "199996         -74.006672         40.739620     1.875  \n",
       "199997         -73.858957         40.692588    12.850  \n",
       "199998         -73.983215         40.695415     3.540  \n",
       "199999         -73.985508         40.768793     5.418  \n",
       "\n",
       "[195472 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f900f7aa",
   "metadata": {},
   "source": [
    "### Process All Data\n",
    "\n",
    "_This is where you can actually execute all the required functions._\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cd53a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_data = get_and_clean_taxi_data()\n",
    "uber_data = get_uber_data()\n",
    "hourly_weather_data, daily_weather_data = load_and_clean_weather_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd101f11",
   "metadata": {},
   "source": [
    "## Part 2: Storing Cleaned Data\n",
    "\n",
    "_Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3529cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2bea0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using SQL (as opposed to SQLAlchemy), define the commands \n",
    "# to create your 4 tables/dataframes\n",
    "HOURLY_WEATHER_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS hourly_weather\n",
    "(\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    datetime DATETIME,\n",
    "    hourly_precipitation FLOAT,\n",
    "    hourly_wind_speed FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "DAILY_WEATHER_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS daily_weather\n",
    "(\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    date DATE,\n",
    "    daily_wind_speed FLOAT,\n",
    "    daily_precipitation FLOAT,\n",
    "    sunrise INT32,\n",
    "    sunset INT32\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "TAXI_TRIPS_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS taxi_trips\n",
    "(\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    pickup_datetime DATETIME,\n",
    "    pickup_longitude FLOAT,\n",
    "    pickup_latitude FLOAT,\n",
    "    dropoff_longitude FLOAT,\n",
    "    dropoff_latitude FLOAT,\n",
    "    distance FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "UBER_TRIPS_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS uber_trips\n",
    "(\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    pickup_datetime DATETIME,\n",
    "    pickup_longitude FLOAT,\n",
    "    pickup_latitude FLOAT,\n",
    "    dropoff_longitude FLOAT,\n",
    "    dropoff_latitude FLOAT,\n",
    "    distance FLOAT\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f41e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open(DATABASE_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(HOURLY_WEATHER_SCHEMA)\n",
    "    f.write(DAILY_WEATHER_SCHEMA)\n",
    "    f.write(TAXI_TRIPS_SCHEMA)\n",
    "    f.write(UBER_TRIPS_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "02eccdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tables with the schema files\n",
    "with engine.connect() as connection:\n",
    "    sql = open(DATABASE_SCHEMA_FILE, \"r\")\n",
    "    commands = sql.read().split(\";\")\n",
    "    sql.close()\n",
    "    for command in commands:\n",
    "        connection.execute(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c122964f",
   "metadata": {},
   "source": [
    "### Add Data to Database\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e68a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframes_to_table(table_to_df_dict):\n",
    "    for name, table in table_to_df_dict.items():\n",
    "        table.to_sql(name, engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45d6c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_table_name_to_dataframe = {\n",
    "    \"taxi_trips\": taxi_data,\n",
    "    \"uber_trips\": uber_data,\n",
    "    \"hourly_weather\": hourly_weather_data,\n",
    "    \"daily_weather\": daily_weather_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74004f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframes_to_table(map_table_name_to_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6e33e",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4753fcd",
   "metadata": {},
   "source": [
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
    "\n",
    "* [ ] For 01-2009 through 06-2015, what hour of the day was the most popular to take a yellow taxi? The result should have 24 bins.\n",
    "* [ ] For the same time frame, what day of the week was the most popular to take an uber? The result should have 7 bins.\n",
    "* [ ] What is the 95% percentile of distance traveled for all hired trips during July 2013?\n",
    "* [ ] What were the top 10 days with the highest number of hired rides for 2009, and what was the average distance for each day?\n",
    "* [ ] Which 10 days in 2014 were the windiest, and how many hired trips were made on those days?\n",
    "* [ ] During Hurricane Sandy in NYC (Oct 29-30, 2012) and the week leading up to it, how many trips were taken each hour, and for each hour, how much precipitation did NYC receive and what was the sustained wind speed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6a849e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_query_to_file(query, outfile):\n",
    "    with open(outfile, \"w\") as f:\n",
    "        f.write(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70a777",
   "metadata": {},
   "source": [
    "### Query N\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._\n",
    "\n",
    "_Repeat for each query_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828ff359",
   "metadata": {},
   "source": [
    "For 01-2009 through 06-2015, what hour of the day was the most popular to take a yellow taxi? The result should have 24 bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db871d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_1 = \"\"\"\n",
    "SELECT strftime('%H', pickup_datetime) AS time, COUNT(*) AS number\n",
    "FROM taxi_trips\n",
    "GROUP BY time\n",
    "ORDER BY number DESC;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5275f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('19', 12476),\n",
       " ('18', 11819),\n",
       " ('20', 11558),\n",
       " ('21', 11502),\n",
       " ('22', 10985),\n",
       " ('14', 10249),\n",
       " ('13', 9808),\n",
       " ('23', 9772),\n",
       " ('12', 9670),\n",
       " ('17', 9623),\n",
       " ('15', 9484),\n",
       " ('11', 9248),\n",
       " ('09', 9026),\n",
       " ('08', 8997),\n",
       " ('10', 8994),\n",
       " ('16', 8242),\n",
       " ('00', 7836),\n",
       " ('07', 7023),\n",
       " ('01', 5775),\n",
       " ('02', 4356),\n",
       " ('06', 4032),\n",
       " ('03', 3199),\n",
       " ('04', 2282),\n",
       " ('05', 1943)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(QUERY_1).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2ef04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_1, \"most_popular_hour.sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "198a304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_2 = \"\"\"\n",
    "SELECT strftime('%w', pickup_datetime) AS day, COUNT(*) AS number\n",
    "FROM uber_trips\n",
    "GROUP BY day\n",
    "ORDER BY number DESC;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5fb4a26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('5', 30166),\n",
       " ('6', 29599),\n",
       " ('4', 29338),\n",
       " ('3', 28328),\n",
       " ('2', 27526),\n",
       " ('0', 25834),\n",
       " ('1', 24681)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(QUERY_2).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5c67cc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_2, \"most_popular_day.sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8817237e",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_3 = \"\"\"\n",
    "WITH hired_trips AS\n",
    "(\n",
    "    SELECT pickup_datetime, distance FROM taxi_trips \n",
    "    WHERE pickup_datetime BETWEEN '2013-07-01' AND '2013-08-01'\n",
    "    UNION ALL\n",
    "    SELECT pickup_datetime, distance FROM uber_trips\n",
    "    WHERE pickup_datetime BETWEEN '2013-07-01' AND '2013-08-01'\n",
    ")\n",
    "SELECT distance\n",
    "FROM hired_trips\n",
    "ORDER BY distance\n",
    "LIMIT 1\n",
    "OFFSET (SELECT COUNT(*) FROM hired_trips) * 95 / 100 - 1 ;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "251d1303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9.948,)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(QUERY_3).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "073d68df",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_3, \"95%_percentile_distance.sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "67614e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_4 = \"\"\"\n",
    "WITH hired_trips AS\n",
    "(\n",
    "    SELECT pickup_datetime, distance FROM taxi_trips \n",
    "    WHERE pickup_datetime BETWEEN '2009-01-01' AND '2010-01-01'\n",
    "    UNION ALL\n",
    "    SELECT pickup_datetime, distance FROM uber_trips\n",
    "    WHERE pickup_datetime BETWEEN '2009-01-01' AND '2010-01-01'\n",
    ")\n",
    "SELECT DATE(pickup_datetime) AS date, COUNT(*) AS number, printf(\"%.4f\",AVG(distance)) AS avg_distance\n",
    "FROM hired_trips\n",
    "GROUP BY date\n",
    "ORDER BY number DESC\n",
    "LIMIT 10;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c63b40ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2009-12-11', 251, '2.9105'),\n",
       " ('2009-06-05', 226, '2.7465'),\n",
       " ('2009-08-14', 223, '3.1896'),\n",
       " ('2009-02-20', 219, '2.7915'),\n",
       " ('2009-05-16', 218, '2.9435'),\n",
       " ('2009-12-05', 215, '3.1627'),\n",
       " ('2009-10-23', 214, '2.8785'),\n",
       " ('2009-05-21', 213, '3.3273'),\n",
       " ('2009-03-12', 211, '2.9953'),\n",
       " ('2009-11-05', 209, '3.1431')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(QUERY_4).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "74723ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_4, \"top_10_days.sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "77c3549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_5 = \"\"\"\n",
    "WITH hired_trips AS\n",
    "(\n",
    "    SELECT DATE(pickup_datetime) AS date FROM taxi_trips\n",
    "    WHERE date BETWEEN '2014-01-01' AND '2015-01-01'\n",
    "    UNION ALL\n",
    "    SELECT DATE(pickup_datetime) AS date FROM uber_trips\n",
    "    WHERE date BETWEEN '2014-01-01' AND '2015-01-01'\n",
    ")\n",
    "SELECT hired_trips.date as date, printf(\"%.4f\",daily_wind_speed), COUNT(*) AS number\n",
    "FROM hired_trips\n",
    "JOIN daily_weather ON hired_trips.date = DATE(daily_weather.date)\n",
    "GROUP BY hired_trips.date\n",
    "ORDER BY daily_wind_speed DESC\n",
    "LIMIT 10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a755bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2014-03-13', '14.0000', 198),\n",
       " ('2014-01-07', '13.0833', 175),\n",
       " ('2014-01-02', '12.7273', 128),\n",
       " ('2014-02-13', '12.2264', 139),\n",
       " ('2014-03-26', '11.9545', 172),\n",
       " ('2014-03-29', '11.9149', 195),\n",
       " ('2014-12-07', '11.6000', 149),\n",
       " ('2014-12-09', '11.2692', 168),\n",
       " ('2014-12-08', '11.2667', 156),\n",
       " ('2014-11-02', '10.8261', 147)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(QUERY_5).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "56e7890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_5, \"windiest_10_days.sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2d555ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_6 = \"\"\"\n",
    "WITH hired_trips AS\n",
    "(\n",
    "    SELECT strftime('%Y-%m-%d %H',pickup_datetime) AS trip_hour FROM taxi_trips\n",
    "    WHERE pickup_datetime BETWEEN '2012-10-22' AND '2012-10-31'\n",
    "    UNION ALL\n",
    "    SELECT strftime('%Y-%m-%d %H',pickup_datetime) AS trip_hour FROM uber_trips\n",
    "    WHERE pickup_datetime BETWEEN '2012-10-22' AND '2012-10-31'\n",
    "),\n",
    "hurricane_weather AS\n",
    "(\n",
    "    SELECT strftime('%Y-%m-%d %H',datetime) AS weather_hour, hourly_precipitation, hourly_wind_speed FROM hourly_weather\n",
    "    WHERE datetime BETWEEN '2012-10-22' AND '2012-10-31'\n",
    ")\n",
    "SELECT weather_hour, COALESCE(COUNT(trip_hour),0) AS number, hourly_precipitation, hourly_wind_speed\n",
    "FROM hurricane_weather\n",
    "LEFT JOIN hired_trips\n",
    "ON trip_hour = weather_hour\n",
    "GROUP BY weather_hour\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3c32b8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2012-10-22 00', 4, 0.0, 7.0),\n",
       " ('2012-10-22 01', 0, 0.0, 5.0),\n",
       " ('2012-10-22 02', 2, 0.0, 7.0),\n",
       " ('2012-10-22 03', 1, 0.0, 0.0),\n",
       " ('2012-10-22 04', 0, 0.0, 0.0),\n",
       " ('2012-10-22 05', 3, 0.0, 0.0),\n",
       " ('2012-10-22 06', 8, 0.0, 5.0),\n",
       " ('2012-10-22 07', 9, 0.0, 3.0),\n",
       " ('2012-10-22 08', 4, 0.0, 3.0),\n",
       " ('2012-10-22 09', 12, 0.0, 5.0),\n",
       " ('2012-10-22 10', 6, 0.0, 0.0),\n",
       " ('2012-10-22 11', 10, 0.0, 0.0),\n",
       " ('2012-10-22 12', 8, 0.0, 11.0),\n",
       " ('2012-10-22 13', 11, 0.0, 0.0),\n",
       " ('2012-10-22 14', 5, 0.0, 7.0),\n",
       " ('2012-10-22 15', 5, 0.0, 6.0),\n",
       " ('2012-10-22 16', 8, 0.0, 3.0),\n",
       " ('2012-10-22 17', 9, 0.0, 7.0),\n",
       " ('2012-10-22 18', 12, 0.0, 5.0),\n",
       " ('2012-10-22 19', 11, 0.0, 5.0),\n",
       " ('2012-10-22 20', 7, 0.0, 3.0),\n",
       " ('2012-10-22 21', 7, 0.0, 0.0),\n",
       " ('2012-10-22 22', 11, 0.0, 3.0),\n",
       " ('2012-10-22 23', 1, 0.0, 3.0),\n",
       " ('2012-10-23 00', 5, 0.0, 3.0),\n",
       " ('2012-10-23 01', 2, 0.0, 0.0),\n",
       " ('2012-10-23 02', 1, 0.0, 3.0),\n",
       " ('2012-10-23 03', 0, 0.0, 0.0),\n",
       " ('2012-10-23 04', 0, 0.0, 3.0),\n",
       " ('2012-10-23 05', 2, 0.0, 0.0),\n",
       " ('2012-10-23 06', 5, 0.0, 0.0),\n",
       " ('2012-10-23 07', 10, 0.0, 0.0),\n",
       " ('2012-10-23 08', 13, 0.0, 0.0),\n",
       " ('2012-10-23 09', 9, 0.0, 3.0),\n",
       " ('2012-10-23 10', 10, 0.0, 0.0),\n",
       " ('2012-10-23 11', 8, 0.0, 3.0),\n",
       " ('2012-10-23 12', 6, 0.0, 0.0),\n",
       " ('2012-10-23 13', 6, 0.0, 0.0),\n",
       " ('2012-10-23 14', 15, 0.0, 0.0),\n",
       " ('2012-10-23 15', 9, 0.0, 0.0),\n",
       " ('2012-10-23 16', 3, 0.0, 3.0),\n",
       " ('2012-10-23 18', 9, 0.0, 5.0),\n",
       " ('2012-10-23 19', 9, 0.0, 0.0),\n",
       " ('2012-10-23 20', 13, 0.02, 0.0),\n",
       " ('2012-10-23 21', 9, 0.0, 5.0),\n",
       " ('2012-10-23 22', 10, 0.01, 0.0),\n",
       " ('2012-10-23 23', 7, 0.0, 5.0),\n",
       " ('2012-10-24 00', 0, 0.0, 3.0),\n",
       " ('2012-10-24 01', 2, 0.0, 6.0),\n",
       " ('2012-10-24 02', 16, 0.0, 5.0),\n",
       " ('2012-10-24 03', 0, 0.0, 7.0),\n",
       " ('2012-10-24 04', 1, 0.0, 7.0),\n",
       " ('2012-10-24 05', 3, 0.0, 6.0),\n",
       " ('2012-10-24 06', 2, 0.0, 5.0),\n",
       " ('2012-10-24 07', 18, 0.0, 5.0),\n",
       " ('2012-10-24 08', 4, 0.0, 0.0),\n",
       " ('2012-10-24 09', 14, 0.0, 0.0),\n",
       " ('2012-10-24 10', 8, 0.0, 7.0),\n",
       " ('2012-10-24 11', 9, 0.0, 7.0),\n",
       " ('2012-10-24 12', 33, 0.0, 8.0),\n",
       " ('2012-10-24 13', 8, 0.0, 8.0),\n",
       " ('2012-10-24 14', 14, 0.0, 6.0),\n",
       " ('2012-10-24 15', 8, 0.0, 7.0),\n",
       " ('2012-10-24 16', 3, 0.0, 8.0),\n",
       " ('2012-10-24 17', 12, 0.0, 5.0),\n",
       " ('2012-10-24 18', 7, 0.0, 7.0),\n",
       " ('2012-10-24 19', 11, 0.0, 8.0),\n",
       " ('2012-10-24 20', 26, 0.0, 0.0),\n",
       " ('2012-10-24 21', 28, 0.0, 3.0),\n",
       " ('2012-10-24 22', 30, 0.0, 5.0),\n",
       " ('2012-10-24 23', 8, 0.0, 0.0),\n",
       " ('2012-10-25 00', 18, 0.0, 6.0),\n",
       " ('2012-10-25 01', 2, 0.0, 3.0),\n",
       " ('2012-10-25 02', 16, 0.0, 3.0),\n",
       " ('2012-10-25 03', 2, 0.0, 6.0),\n",
       " ('2012-10-25 04', 2, 0.0, 6.0),\n",
       " ('2012-10-25 05', 2, 0.0, 0.0),\n",
       " ('2012-10-25 06', 9, 0.0, 5.0),\n",
       " ('2012-10-25 07', 5, 0.0, 6.0),\n",
       " ('2012-10-25 08', 12, 0.0, 5.0),\n",
       " ('2012-10-25 09', 8, 0.0, 3.0),\n",
       " ('2012-10-25 10', 9, 0.0, 6.0),\n",
       " ('2012-10-25 11', 8, 0.0, 0.0),\n",
       " ('2012-10-25 12', 14, 0.0, 6.0),\n",
       " ('2012-10-25 13', 6, 0.0, 0.0),\n",
       " ('2012-10-25 14', 9, 0.0, 5.0),\n",
       " ('2012-10-25 15', 8, 0.0, 5.0),\n",
       " ('2012-10-25 16', 4, 0.0, 0.0),\n",
       " ('2012-10-25 17', 5, 0.0, 3.0),\n",
       " ('2012-10-25 18', 8, 0.0, 0.0),\n",
       " ('2012-10-25 19', 9, 0.0, 0.0),\n",
       " ('2012-10-25 20', 15, 0.0, 3.0),\n",
       " ('2012-10-25 21', 13, 0.0, 3.0),\n",
       " ('2012-10-25 22', 11, 0.0, 3.0),\n",
       " ('2012-10-25 23', 9, 0.0, 0.0),\n",
       " ('2012-10-26 00', 21, 0.0, 0.0),\n",
       " ('2012-10-26 01', 4, 0.0, 0.0),\n",
       " ('2012-10-26 02', 3, 0.0, 0.0),\n",
       " ('2012-10-26 03', 4, 0.0, 3.0),\n",
       " ('2012-10-26 04', 4, 0.0, 0.0),\n",
       " ('2012-10-26 05', 1, 0.0, 0.0),\n",
       " ('2012-10-26 06', 0, 0.0, 0.0),\n",
       " ('2012-10-26 07', 7, 0.0, 3.0),\n",
       " ('2012-10-26 08', 7, 0.0, 3.0),\n",
       " ('2012-10-26 09', 13, 0.0, 3.0),\n",
       " ('2012-10-26 10', 5, 0.0, 3.0),\n",
       " ('2012-10-26 11', 14, 0.0, 3.0),\n",
       " ('2012-10-26 12', 7, 0.0, 0.0),\n",
       " ('2012-10-26 13', 8, 0.0, 3.0),\n",
       " ('2012-10-26 14', 9, 0.0, 3.0),\n",
       " ('2012-10-26 15', 4, 0.0, 0.0),\n",
       " ('2012-10-26 16', 5, 0.0, 0.0),\n",
       " ('2012-10-26 17', 7, 0.0, 0.0),\n",
       " ('2012-10-26 18', 8, 0.0, 0.0),\n",
       " ('2012-10-26 19', 10, 0.0, 0.0),\n",
       " ('2012-10-26 20', 15, 0.0, 3.0),\n",
       " ('2012-10-26 21', 5, 0.0, 3.0),\n",
       " ('2012-10-26 22', 12, 0.0, 0.0),\n",
       " ('2012-10-26 23', 9, 0.0, 0.0),\n",
       " ('2012-10-27 00', 10, 0.0, 3.0),\n",
       " ('2012-10-27 01', 5, 0.0, 0.0),\n",
       " ('2012-10-27 02', 10, 0.0, 3.0),\n",
       " ('2012-10-27 03', 7, 0.0, 0.0),\n",
       " ('2012-10-27 04', 1, 0.0, 6.0),\n",
       " ('2012-10-27 05', 3, 0.0, 6.0),\n",
       " ('2012-10-27 06', 3, 0.0, 6.0),\n",
       " ('2012-10-27 07', 10, 0.0, 5.0),\n",
       " ('2012-10-27 08', 3, 0.0, 5.0),\n",
       " ('2012-10-27 09', 10, 0.0, 6.0),\n",
       " ('2012-10-27 10', 12, 0.0, 7.0),\n",
       " ('2012-10-27 11', 32, 0.0, 5.0),\n",
       " ('2012-10-27 12', 7, 0.0, 8.0),\n",
       " ('2012-10-27 13', 8, 0.0, 8.0),\n",
       " ('2012-10-27 14', 6, 0.0, 10.0),\n",
       " ('2012-10-27 15', 10, 0.0, 10.0),\n",
       " ('2012-10-27 16', 13, 0.0, 7.0),\n",
       " ('2012-10-27 17', 16, 0.0, 7.0),\n",
       " ('2012-10-27 18', 11, 0.0, 7.0),\n",
       " ('2012-10-27 19', 39, 0.0, 8.0),\n",
       " ('2012-10-27 20', 12, 0.0, 7.0),\n",
       " ('2012-10-27 21', 18, 0.0, 9.0),\n",
       " ('2012-10-27 22', 18, 0.0, 9.0),\n",
       " ('2012-10-27 23', 12, 0.0, 8.0),\n",
       " ('2012-10-28 00', 8, 0.0, 11.0),\n",
       " ('2012-10-28 01', 14, 0.0, 8.0),\n",
       " ('2012-10-28 02', 4, 0.0, 8.0),\n",
       " ('2012-10-28 03', 8, 0.0, 9.0),\n",
       " ('2012-10-28 04', 12, 0.0, 10.0),\n",
       " ('2012-10-28 05', 2, 0.0, 11.0),\n",
       " ('2012-10-28 06', 0, 0.0, 10.0),\n",
       " ('2012-10-28 07', 4, 0.0, 11.0),\n",
       " ('2012-10-28 08', 4, 0.0, 11.0),\n",
       " ('2012-10-28 09', 7, 0.0, 11.0),\n",
       " ('2012-10-28 10', 7, 0.0, 10.0),\n",
       " ('2012-10-28 11', 7, 0.0, 8.0),\n",
       " ('2012-10-28 12', 6, 0.0, 7.0),\n",
       " ('2012-10-28 13', 8, 0.0, 13.0),\n",
       " ('2012-10-28 14', 8, 0.0, 13.0),\n",
       " ('2012-10-28 15', 7, 0.0, 13.0),\n",
       " ('2012-10-28 16', 6, 0.0, 16.0),\n",
       " ('2012-10-28 17', 10, 0.0, 11.0),\n",
       " ('2012-10-28 18', 7, 0.0, 15.0),\n",
       " ('2012-10-28 19', 3, 0.0, 14.0),\n",
       " ('2012-10-28 20', 8, 0.0, 16.0),\n",
       " ('2012-10-28 21', 4, 0.0, 14.0),\n",
       " ('2012-10-28 22', 4, 0.0, 16.0),\n",
       " ('2012-10-28 23', 3, 0.0, 14.0),\n",
       " ('2012-10-29 00', 2, 0.0, 16.0),\n",
       " ('2012-10-29 01', 1, 0.0, 11.0),\n",
       " ('2012-10-29 02', 1, 0.0, 13.0),\n",
       " ('2012-10-29 03', 1, 0.0, 17.0),\n",
       " ('2012-10-29 04', 1, 0.0, 15.0),\n",
       " ('2012-10-29 05', 0, 0.0, 15.0),\n",
       " ('2012-10-29 06', 1, 0.02, 16.0),\n",
       " ('2012-10-29 07', 2, 0.02, 17.0),\n",
       " ('2012-10-29 08', 2, 0.0, 21.0),\n",
       " ('2012-10-29 09', 2, 0.0, 16.0),\n",
       " ('2012-10-29 10', 2, 0.0, 0.0),\n",
       " ('2012-10-29 11', 12, 0.0, 21.0),\n",
       " ('2012-10-29 12', 30, 0.02, 15.0),\n",
       " ('2012-10-29 13', 3, 0.02, 24.0),\n",
       " ('2012-10-29 14', 12, 0.03, 23.0),\n",
       " ('2012-10-29 15', 4, 0.07, 26.0),\n",
       " ('2012-10-29 16', 0, 0.1, 23.0),\n",
       " ('2012-10-29 17', 4, 0.04, 29.0),\n",
       " ('2012-10-29 18', 6, 0.02, 21.0),\n",
       " ('2012-10-29 19', 0, 0.01, 25.0),\n",
       " ('2012-10-29 20', 0, 0.0, 17.0),\n",
       " ('2012-10-29 21', 2, 0.0, 15.0),\n",
       " ('2012-10-29 22', 0, 0.02, 9.0),\n",
       " ('2012-10-29 23', 0, 0.03, 7.0),\n",
       " ('2012-10-30 00', 2, 0.03, 13.0),\n",
       " ('2012-10-30 01', 0, 0.0, 13.0),\n",
       " ('2012-10-30 02', 0, 0.03, 9.0),\n",
       " ('2012-10-30 03', 0, 0.04, 17.0),\n",
       " ('2012-10-30 04', 1, 0.0, 9.0),\n",
       " ('2012-10-30 05', 0, 0.01, 7.0),\n",
       " ('2012-10-30 06', 0, 0.01, 7.0),\n",
       " ('2012-10-30 07', 0, 0.0, 10.0),\n",
       " ('2012-10-30 08', 4, 0.01, 11.0),\n",
       " ('2012-10-30 09', 12, 0.01, 15.0),\n",
       " ('2012-10-30 10', 12, 0.02, 8.0),\n",
       " ('2012-10-30 11', 5, 0.0, 7.0),\n",
       " ('2012-10-30 12', 4, 0.0, 9.0),\n",
       " ('2012-10-30 13', 16, 0.0, 7.0),\n",
       " ('2012-10-30 14', 12, 0.0, 0.0),\n",
       " ('2012-10-30 15', 5, 0.0, 0.0),\n",
       " ('2012-10-30 16', 15, 0.01, 3.0),\n",
       " ('2012-10-30 17', 12, 0.0, 6.0),\n",
       " ('2012-10-30 18', 5, 0.0, 5.0),\n",
       " ('2012-10-30 19', 5, 0.0, 3.0),\n",
       " ('2012-10-30 20', 4, 0.0, 0.0),\n",
       " ('2012-10-30 21', 3, 0.0, 5.0),\n",
       " ('2012-10-30 22', 6, 0.0, 7.0),\n",
       " ('2012-10-30 23', 8, 0.0, 5.0)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(QUERY_6).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c1cc0055",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_6, \"hurricane_sandy.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ced42",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data\n",
    "\n",
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
    "\n",
    "* [ ] Create an appropriate visualization for the first query/question in part 3\n",
    "* [ ] Create a visualization that shows the average distance traveled per month (regardless of year - so group by each month). Include the 90% confidence interval around the mean in the visualization\n",
    "* [ ] Define three lat/long coordinate boxes around the three major New York airports: LGA, JFK, and EWR (you can use bboxfinder to help). Create a visualization that compares what day of the week was most popular for drop offs for each airport.\n",
    "* [ ] Create a heatmap of all hired trips over a map of the area. Consider using KeplerGL or another library that helps generate geospatial visualizations.\n",
    "* [ ] Create a scatter plot that compares tip amount versus distance.\n",
    "* [ ] Create another scatter plot that compares tip amount versus precipitation amount.\n",
    "\n",
    "_Be sure these cells are executed so that the visualizations are rendered when the notebook is submitted._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9eef42",
   "metadata": {},
   "source": [
    "### Visualization N\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._\n",
    "\n",
    "_Repeat for each visualization._\n",
    "\n",
    "_The example below makes use of the `matplotlib` library. There are other libraries, including `pandas` built-in plotting library, kepler for geospatial data representation, `seaborn`, and others._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_n(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ced2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_n():\n",
    "    # Query SQL database for the data needed.\n",
    "    # You can put the data queried into a pandas dataframe, if you wish\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_n()\n",
    "plot_visual_n(some_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
